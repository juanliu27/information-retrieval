{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import bisect\n",
    "from collections import defaultdict\n",
    "import jieba\n",
    "import jieba_fast\n",
    "import pickle\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySearch():\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    filename : str\n",
    "        file name of doc data\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    load_data(filename):\n",
    "        load data from file.\n",
    "    save_data(filename):\n",
    "        save data to file\n",
    "    pre_cache_all():\n",
    "        Pre-caching all words in docs.\n",
    "    BM25score(text, keyword):\n",
    "        get BM25score of text for a query.\n",
    "    BM25init(doc_list):\n",
    "        initializing BM25 model\n",
    "    search(keyword, num=15):\n",
    "        get top num search results of a query.\n",
    "    render(result_list, keyword):\n",
    "        output search results with highlight.\n",
    "    query_to_set_expression(query):\n",
    "        convert bool query to set expression(for eval process).\n",
    "    get_word_match(word):\n",
    "        get match set of the word.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filename): \n",
    "        self.docs = [] \n",
    "        self.docs_lower = []\n",
    "        self.search_cache = defaultdict(set)\n",
    "        self.doc_count=0\n",
    "        self.avgdl=0\n",
    "        self.df=defaultdict(int)\n",
    "        self.stop_word_set=set([' ','$','——','-','.',',','/', '，', '；', \\\n",
    "                                '？','！','。','、','：','“','”',';',\\\n",
    "                                '@','是','让','了','的','啊','吧']) \n",
    "        jieba.load_userdict(\"dict.txt\")\n",
    "        self.load_data(filename)#读取文件\n",
    "        \n",
    "        \n",
    "    def load_data(self, filename): #读取数据\n",
    "        if filename[-3:] == 'txt': \n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                self.docs = f.read().split('\\n') \n",
    "            self.docs_lower = [doc.lower() for doc in self.docs] \n",
    "            self.pre_cache_all() \n",
    "        elif filename[-3:] == 'dat':\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.docs, self.docs_lower, self.search_cache = pickle.load(f)\n",
    "    \n",
    "    def pre_cache_all(self): #提前加载cache\n",
    "        doc_length_sum = 0\n",
    "        for tid, doc in enumerate(self.docs_lower): \n",
    "            for word in jieba.cut_for_search(doc): \n",
    "                self.search_cache[word].add(tid) #出现过的词进入倒排索引                \n",
    "    \n",
    "    def query_to_set_expression(self, query): #转换\n",
    "        query_new_parts = []\n",
    "        all_parts = list(query.replace('(', ' ( ').replace(')', ' ) ').split())\n",
    "        idx = 0\n",
    "        cache = ''\n",
    "        count_parts = len(all_parts)\n",
    "        while idx < count_parts: \n",
    "            if all_parts[idx] == '(' or all_parts[idx] == ')':\n",
    "                query_new_parts.append(all_parts[idx]) \n",
    "            elif all_parts[idx] == ' ' or all_parts[idx] == '': \n",
    "                query_new_parts.append(' ') \n",
    "            elif all_parts[idx] in ('and', 'AND', '+'):\n",
    "                query_new_parts.append('&')\n",
    "            elif all_parts[idx] in ('or', 'OR'):\n",
    "                query_new_parts.append('|')\n",
    "            elif all_parts[idx] in ('not', 'NOT', '-'): \n",
    "                query_new_parts.append('-')\n",
    "            else:\n",
    "                if cache:\n",
    "                    cache += ' ' + all_parts[idx] \n",
    "                else:\n",
    "                    cache = all_parts[idx] \n",
    "\n",
    "                if (idx + 1 == count_parts\n",
    "                  or all_parts[idx + 1] in ('(', ')', 'and', 'AND', '+', 'or', 'OR', 'NOT', 'not', '+', '-', ' ', '')):\n",
    "                    query_new_parts.append(\"self.get_word_match('{}')\".format(cache)) \n",
    "                    cache = ''\n",
    "            idx += 1\n",
    "        query_new = ''.join(query_new_parts)\n",
    "        return query_new #id\n",
    "    \n",
    "    def get_word_match(self, word):#转换tid\n",
    "        if_first_subword = True\n",
    "        result = None\n",
    "        for term in list(jieba.cut(word)):\n",
    "            if if_first_subword:\n",
    "                result = self.search_cache[term] \n",
    "                if_first_subword = False\n",
    "            else:\n",
    "                result = result & self.search_cache[term]\n",
    "            if not result:\n",
    "                break\n",
    "        return result\n",
    "    \n",
    "    def BM25init(self,doc_list): #初始化BM25模型\n",
    "        doc_length_sum=0\n",
    "        self.doc_count=len(self.docs_lower)   #N\n",
    "        for doc in doc_list:\n",
    "            doc_length_sum += len(doc)  \n",
    "            for word in set(jieba.cut(doc.lower())): \n",
    "                self.df[word]+=1  #n\n",
    "        self.avgdl = doc_length_sum/self.doc_count #avgdl\n",
    "        \n",
    "        \n",
    "    def BM25score(self,doc,query,k1 = 1.5,b=0.75):#BM25score    \n",
    "        result=0\n",
    "        word_list=list(jieba.cut(doc))    \n",
    "        dl=len(doc) # dl\n",
    "        for word in query:\n",
    "            f = doc.count(word) # f\n",
    "            idf=math.log10((self.doc_count-self.df[word]+0.5)/(self.df[word]+0.5)+1)\n",
    "            r=f*(k1+1)/(f+k1*(1-b+b*(dl/self.avgdl)))\n",
    "            result+=r*idf       \n",
    "        return result\n",
    "    \n",
    "    #最新的\n",
    "    def search(self, query): \n",
    "        query_lower = query.lower()   \n",
    "        result_list = []\n",
    "        min_score = 0 \n",
    "        query_new = self.query_to_set_expression(query_lower) \n",
    "        match_tid_list=list(eval(query_new))#查询结果tid\n",
    "        query_fresh=set(jieba.cut(query.lower()))-set(['(',')','and','or','not','-',' ','','AND','+','OR','NOT'])\n",
    "        self.BM25init([self.docs_lower[tid] for tid in match_tid_list])#初始化BM25模型\n",
    "        result_list=[(tid,self.BM25score(self.docs_lower[tid],query_fresh)) for tid in match_tid_list] #查询结果BM25结果打分\n",
    "        result_list.sort(key=lambda x:x[1],reverse=True) #排序\n",
    "        return [doc_id for doc_id, _ in result_list]\n",
    "\n",
    "    \n",
    "    def render(self, result_list, keyword): #展示函数\n",
    "        count = 1\n",
    "        print(\"共检索出\",len(result_list),\"条数据\",\"\\n\",\"--------------分割线-------------\")\n",
    "        for item in result_list:\n",
    "            result = self.docs[item].replace('$$$', '<br/>') \n",
    "            display(HTML(\"{}、{}......\".format(count,result[:100]))) #输出内容\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 779 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "searcher=MySearch('titles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 70.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query='新能源 AND (特斯拉 or 小鹏) '\n",
    "search_result=searcher.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共检索出 4 条数据 \n",
      " --------------分割线-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "1、一个月内近40款新能源汽车涨价：最高超3万元<br/>近日，中国新能源汽车受原材料价格上涨影响，一度掀起了“涨价潮”。据统计，例如零跑C11涨幅在13%-15%；特斯拉涨幅最高的车型是ModelY，各......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2、动力电池原材料价格疯涨 车企扛不住了！工信部出手<br/>近段时间，国内的动力电池价格持续走高，倒逼新能源整车企业上涨整车售价，小鹏、比亚迪、零跑、几何、长城、奇瑞等一众新能源车企，都宣布涨价数千至数......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3、美国厂商要求分享汽车电池技术 韩国犯难：无奈<br/>除了特斯拉之外，通用、福特等美国三大汽车巨头也开始加码电动车，对汽车电池的需求高涨，韩国公司也纷纷到美国设立电池工厂，然而通用汽车要求这些厂商分享......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4、华为鸿蒙座舱加持 长安C385实车曝光：有保时捷那味了<br/>近日消息，长安新能源官方公布了全新车型C385的更多信息。据悉，该车是长安全新专用电动车平台首款车型，，此外，官方还公布了该车的高宽比：......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "searcher.render(search_result,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
