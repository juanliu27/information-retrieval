{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import bisect\n",
    "from collections import defaultdict\n",
    "import jieba\n",
    "import pickle\n",
    "\n",
    "class MySearchC5V0():\n",
    "    \"\"\"\n",
    "    C3V0: Base class for Search Engine.\n",
    "    C3V1: Data multiplication added.\n",
    "    C3V2: Sorting optimization.\n",
    "    C3V3: Add lowered version of docs.\n",
    "    C3V4: For long doc.\n",
    "    C3V5: Caching search results.\n",
    "    C3V6: Pre-caching all words in docs.\n",
    "    C3V7: Add Serialize/UnSerialize.\n",
    "    C4V1: Add basic Bool query support\n",
    "    C4V2: Add wordseg to get_word_match()\n",
    "    ----------------C5V0-----------------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    filename : str\n",
    "        file name of doc data\n",
    "    multi_factor : int\n",
    "        data multiplication factor(default 1)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    load_data(filename):\n",
    "        load data from file.\n",
    "    save_data(filename):\n",
    "        save data to file\n",
    "    pre_cache_all():\n",
    "        Pre-caching all words in docs.\n",
    "    highlight(text, keyword):\n",
    "        highlight text with keyword.\n",
    "    score(text, keyword):\n",
    "        get score of text for a query.\n",
    "    get_word_match(self, keyword):\n",
    "        get doc set containing keyword.\n",
    "    search(keyword, num=15):\n",
    "        get top num search results of a query.\n",
    "    render(result_list, keyword):\n",
    "        output search results with highlight.\n",
    "    query_to_set_expression(query):\n",
    "        convert bool query to set expression(for eval process).\n",
    "    get_word_match(word):\n",
    "        get match set of the word.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filename, multi_factor=1):\n",
    "        self.docs = []\n",
    "        self.docs_lower = []\n",
    "        self.search_cache = defaultdict(set)\n",
    "        self.multi_factor = multi_factor\n",
    "        self.load_data(filename)\n",
    "    \n",
    "    def highlight(self, text, keyword, ori_text):\n",
    "        idx = text.find(keyword)\n",
    "        result = text\n",
    "        if idx >= 0:\n",
    "            ori_keyword = ori_text[idx:idx+len(keyword)]\n",
    "            result = ori_text.replace(ori_keyword, '<span style=\"color:red\">{}</span>'.format(ori_keyword))\n",
    "        return result\n",
    "    \n",
    "    def score(self, text, keyword):\n",
    "        result = text.count(keyword)\n",
    "        return result\n",
    "    \n",
    "    def query_to_set_expression(self, query):\n",
    "        query_new_parts = []\n",
    "        all_parts = list(query.replace('(', ' ( ').replace(')', ' ) ').split())\n",
    "        idx = 0\n",
    "        cache = ''\n",
    "        count_parts = len(all_parts)\n",
    "        while idx < count_parts:\n",
    "            if all_parts[idx] == '(' or all_parts[idx] == ')':\n",
    "                query_new_parts.append(all_parts[idx])\n",
    "            elif all_parts[idx] == ' ' or all_parts[idx] == '':\n",
    "                query_new_parts.append(' ')\n",
    "            elif all_parts[idx] in ('and', 'AND', '+'):\n",
    "                query_new_parts.append('&')\n",
    "            elif all_parts[idx] in ('or', 'OR'):\n",
    "                query_new_parts.append('|')\n",
    "            elif all_parts[idx] in ('not', 'NOT', '-'):\n",
    "                query_new_parts.append('-')\n",
    "            else:\n",
    "                if cache:\n",
    "                    cache += ' ' + all_parts[idx]\n",
    "                else:\n",
    "                    cache = all_parts[idx]\n",
    "\n",
    "                if (idx + 1 == count_parts\n",
    "                  or all_parts[idx + 1] in ('(', ')', 'and', 'AND', '+', 'or', 'OR', 'NOT', 'not', '+', '-', ' ', '')):\n",
    "                    query_new_parts.append(\"self.get_word_match('{}')\".format(cache))\n",
    "                    cache = ''\n",
    "            idx += 1\n",
    "        query_new = ''.join(query_new_parts)\n",
    "        return query_new\n",
    "    \n",
    "    def get_word_match(self, word):\n",
    "        if_first_subword = True\n",
    "        result = None\n",
    "        for term in list(jieba.cut(word)):\n",
    "            if if_first_subword:\n",
    "                result = self.search_cache[term]\n",
    "                if_first_subword = False\n",
    "            else:\n",
    "                result = result & self.search_cache[term]\n",
    "            if not result:\n",
    "                break\n",
    "        return result\n",
    "    \n",
    "    def search(self, query, num=15):\n",
    "        query_lower = query.lower()    \n",
    "        result_list = []\n",
    "        min_score = 0\n",
    "        query_new = self.query_to_set_expression(query_lower)\n",
    "        for tid in eval(query_new):\n",
    "            doc = self.docs_lower[tid]\n",
    "            score = 1 #self.score(doc, keyword_lower)\n",
    "            if len(result_list) == num:\n",
    "                if score > min_score:\n",
    "                    insert_idx = bisect.bisect(\n",
    "                        [doc_score[1] for doc_score in result_list], \n",
    "                        score\n",
    "                    )\n",
    "                    min_score = result_list[0][1]\n",
    "                    result_list = result_list[1:insert_idx] + \\\n",
    "                                    [(tid, score)] + \\\n",
    "                                    result_list[insert_idx:]\n",
    "            elif len(result_list) < num - 1:\n",
    "                result_list.append((tid, score))\n",
    "            elif len(result_list) == num - 1:\n",
    "                result_list.append((tid, score))\n",
    "                result_list.sort(key = lambda x: x[1])\n",
    "                min_score = result_list[0][1]\n",
    "        return [doc_id for doc_id, _ in result_list[::-1]]\n",
    "    \n",
    "    def render(self, result_list, keyword):\n",
    "        count = 1\n",
    "        for item in result_list:\n",
    "            result = self.highlight(\n",
    "                self.docs_lower[item], \n",
    "                keyword.lower(), \n",
    "                self.docs[item]\n",
    "            ).replace('$$$', '<br/>') #\n",
    "            display(HTML(\"{}、{}......\".format(count,result[:150]))) #\n",
    "            count += 1\n",
    "            \n",
    "    def pre_cache_all(self):\n",
    "        for tid, doc in enumerate(self.docs_lower):\n",
    "            for word in jieba.cut_for_search(doc):\n",
    "                self.search_cache[word].add(tid)\n",
    "                \n",
    "    def load_data(self, filename):\n",
    "        if filename[-3:] == 'txt':\n",
    "            with open(filename, 'r',encoding='utf-8') as f:\n",
    "                self.docs = f.read().split('\\n')\n",
    "            self.docs_lower = [doc.lower() for doc in self.docs]\n",
    "            self.docs = self.docs * self.multi_factor \n",
    "            self.docs_lower = self.docs_lower * self.multi_factor\n",
    "            self.pre_cache_all()\n",
    "        elif filename[-3:] == 'dat':\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.docs, self.docs_lower, self.search_cache = pickle.load(f)\n",
    "                \n",
    "    def save_data(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump((self.docs, self.docs_lower, self.search_cache), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = 'iphone 手机'\n",
    "\n",
    "doc_1 = 'iPhone 13系列大降价！国产手机难受了$$$华为手机逐渐退出主流市场后，\\\n",
    "其余国产手机品牌抓住机会努力冲击高端市场。但可惜的是，随着苹果iPhone 13的发布，\\\n",
    "国产手机品牌高端化进程受到严重冲击。由于全球缺芯和部分原材料涨价，苹果iPhone 13系列在发布之前被认为会略微涨价。但实际情况是，网友们一直调侃的“十三香”确实应验了，iPhone 13系列的国行售价相比前代iPhone便宜了300元-800元，而美版价格则保持不变。对于中国消费者来说，苹果iPhone 13系列加量不加价自然是一件大好事。但是对于国内的智能手机厂商来说，iPhone 13系列的降价可能会破坏国产手机厂商的高端化进程。我们来看看苹果iPhone 13系列的售价：iPhone 13 mini 128G 版价格为5199元，256GB版5999元、512GB版7599元，iPhone 13 128GB版5999元、256GB版6799元、512GB版8399元。iPhone 13 Pro 128GB版7999元、256GB版8799元、512GB版10399元、1T版11999元，iPhone 13 Pro Max 128GB版8999元、256GB版9799元、512GB版11399元、1T版12999元。除了价格下降以外，iPhone 13系列的各项参数也有不小的提升，尤其是在续航方面。根据知名数码评测博主@小白测评的数据，iPhone 13 Pro Max和iPhone 13两款机型重度使用5小时后，仍旧剩余不少电量。尤其是iPhone 13 Pro Max在五小时深度续航测试中表现十分优秀，剩余电量35%，远超其他智能手机，位列排行榜第一。除此之外，iPhone 13系列另一个最明显的升级是支持120Hz高刷，进一步提升了流畅度。而在拍照、摄影方面，此次iPhone 13系列也同样有较大幅度地升级，特别是电影模式的加入，让手机专业摄影成为可能。在加量不加价后，苹果iPhone 13相较国产安卓高端手机的优势就更大了。目前国产高端手机的价位普遍来到5000-8000元，但是在性能、录影、续航、系统生态体验等方面与iPhone 13存在较大差距，这很可能导致国内高端市场被苹果“垄断”。随着苹果iPhone 13系列降价，并且补齐了续航、高刷新率等短板，安卓旗舰手机是否还值得购买？曾几何时，华为凭借在影像方面的创新一步步站稳高端市场，而华为的成功对于其他国产手机厂商冲击高端市场具有极其深远的借鉴意义。因此，影像成为了安卓旗舰手机对比iPhone 13 Pro为数不多的优势之一。今年苹果iPhone 13系列在相机参数方面并没有大幅升级，主摄依然是1200万像素，但是升级了CMOS图像传感器和光圈，提升了进光量，整体硬件差距仍然和安卓阵营有较大的差距。虽然目前手机影像已经进入计算摄影时代，算法可能比硬件更加重要，但是华为、三星等一众顶级厂商的算法也并不差。因此，凭借更强的硬件素质，安卓高端手机在手机成像质量方面依然是领先苹果iPhone。另外，安卓高端手机的充电功率目前已经进入百瓦时代，部分安卓机型仅需半小时不到时间就可以充满电量。而iPhone 13系列的充电功率仅有20W，充满电量需要一个多小时。因此，如果你特别在意充电速度和拍照成片质量，那么还是建议首选安卓旗舰手机。但如果从综合体验上来看，笔者认为苹果iPhone 13系列的优势更大，除了在性能、录影、续航、系统生态体验等方面的领先优势非常明显以外，iPhone 13系列的拍摄体验也非常棒。虽然成像质量不如安卓旗舰，但是凭借更强的A15处理器，苹果iPhone 13系列带来更加流畅的拍摄体验，比如暗光环境下，一秒就能成片，而安卓旗舰则需要大量时间进行计算。又比如iPhone 13系列拍照时，预览框和成片几乎可以保持一致，做到所见即所得。而安卓旗舰手机的计算性能则无法支持这样的拍摄体验。更低的售价，更好的使用体验，苹果iPhone 13对于安卓旗舰手机来说确实是一个颇为危险的信号。摆在国产手机厂商面前只有两条路：一条路是降低旗舰机型售价，但这会严重影响国产品牌进击高端市场的决心;另一条路是加大研发创新投入，寻找新的差异化优势，建造护城河。 - THE END -     $$$https://news.mydrivers.com/1/785/785198.htm'\n",
    "\n",
    "doc_2 = '小米史上最窄“下巴”！Xiaomi Civi开箱图赏$$$9月22日，小米官宣全新手机系列——Xiaomi Civi，\\\n",
    "定位专为年轻人打造潮流手机，首款机型定档于9月27日发布。现在这款手机已经抢先来到我们评测室，\\\n",
    "下面为大家带来图赏。，在保持丝滑手感的体验之上，蓝色和黑色还带来了BlingBling的闪亮外观，同时不留指纹，而独特的C位粉色版本还带有全新的绒毛纹理。；对手部的负担更小，这对女性用户来说尤其重要。新机配备6.55英寸屏幕，做到了与6.1英寸屏幕的iPhone 13等宽。Xiaomi Civi的精致感不仅来自后盖的工艺和中框的弧度，同时还有极致窄边框， - THE END -转载请注明出处：快科技     $$$https://news.mydrivers.com/1/785/785197.htm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from math import sqrt\n",
    "\n",
    "def score_vsm(doc1,doc2):\n",
    "    stop_word_set=set([' ','$','——','-','.',',','/', '，', '；', '？','！','。','、','：','“','”',';','@','是','让','了','的','啊','吧'])\n",
    "    \n",
    "    word_set_doc1=set(jieba.cut(doc1.lower()))\n",
    "    word_set_doc2=set(jieba.cut(doc2.lower()))\n",
    "    \n",
    "    vocabulary=sorted(list((word_set_doc1| word_set_doc2)-stop_word_set))\n",
    "    \n",
    "    vector_doc1=[1 if word in word_set_doc1 else 0 for word in vocabulary]\n",
    "    vector_doc2=[1 if word in word_set_doc2 else 0 for word in vocabulary]\n",
    "    \n",
    "    cosine=sum([ vector_doc1[i]* vector_doc2[i] for i in range(len(vocabulary))])\\\n",
    "         /(sqrt(sum([ vector_doc1[i]* vector_doc1[i] for i in range(len(vocabulary))]))\\\n",
    "        *sqrt(sum([ vector_doc2[i]* vector_doc2[i] for i in range(len(vocabulary))])))\n",
    "    \n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\01630\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.683 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of doc1:0.0746393370862076\n",
      "score of doc2:0.13074409009212268\n"
     ]
    }
   ],
   "source": [
    "print('score of doc1:{}'.format(score_vsm(q,doc_1)))\n",
    "print('score of doc2:{}'.format(score_vsm(q,doc_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入词频信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_set=set([' ','$','——','-','.',',','/', '，', '；', '？','！','。','、','：','“','”',';','@','是','让','了','的','啊','吧'])\n",
    "word_set_doc1=set(jieba.cut(doc_1.lower()))\n",
    "word_set_doc2=set(jieba.cut(doc_2.lower()))\n",
    "word_set_q=set(jieba.cut(q.lower()))    \n",
    "vocabulary=sorted(list((word_set_doc1| word_set_doc2)-stop_word_set))\n",
    "#print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from math import sqrt\n",
    "\n",
    "def score_vsm(doc1,doc2,vocabulary):\n",
    "    word_list_doc1=list(jieba.cut(doc1.lower()))\n",
    "    word_list_doc2=list(jieba.cut(doc2.lower()))\n",
    "    \n",
    "    vector_doc1=[ word_list_doc1.count(word) for word in vocabulary]\n",
    "    vector_doc2=[ word_list_doc2.count(word) for word in vocabulary]\n",
    "    \n",
    "    cosine=sum([ vector_doc1[i]* vector_doc2[i] for i in range(len(vocabulary))])\\\n",
    "         /(sqrt(sum([ vector_doc1[i]* vector_doc1[i] for i in range(len(vocabulary))]))\\\n",
    "        *sqrt(sum([ vector_doc2[i]* vector_doc2[i] for i in range(len(vocabulary))])))\n",
    "    \n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of doc1:0.39217517025647636\n",
      "score of doc2:0.20739033894608505\n"
     ]
    }
   ],
   "source": [
    "print('score of doc1:{}'.format(score_vsm(q,doc_1,vocabulary)))\n",
    "print('score of doc2:{}'.format(score_vsm(q,doc_2,vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-cf30242001b3>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-cf30242001b3>\"\u001b[1;36m, line \u001b[1;32m24\u001b[0m\n\u001b[1;33m    idf log10()\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from math import sqrt\n",
    "\n",
    "class VSMOneHot():\n",
    "    \"\"\"vector space model-one hot\"\"\"\n",
    "    def __init__(self ,doc_list):\n",
    "        self.stop_word_set=set([' ','$','——','-','.',',','/', '，', '；', \\\n",
    "                                '？','！','。','、','：','“','”',';',\\\n",
    "                                '@','是','让','了','的','啊','吧'])\n",
    "        self.vocabulary=[]\n",
    "        for doc in doc_list:\n",
    "             self.vocabulary+=list(jieba.cut(doc.lower()))\n",
    "        self.vocabulary=sorted(list(set(self.vocabulary)-self.stop_word_set))\n",
    "    \n",
    "    def score(self,q,doc):     #计算文档中每个词的tf-idf,并且利用这些tf-idf构成关于该文档的向量\n",
    "        vector_q=self.vectorize(q)\n",
    "        vector_doc=self.vectorize(doc)\n",
    "        return self.cosine(vector_q,vector_doc)\n",
    "        \n",
    "    def vectorize(self,doc):\n",
    "        result=[]\n",
    "        word_list=list(jieba.cut(doc.lower()))\n",
    "        #word_set=set(jieba.cut(doc.lower()))\n",
    "        for word in self.vocabulary:\n",
    "            tf=word_list.count(word)\n",
    "            idf log10()\n",
    "        return result\n",
    "    \n",
    "    def dot(self,vec1,vec2):\n",
    "        return [ vec1[i]* vec2[i] for i in range(len(self.vocabulary))]\n",
    "    \n",
    "    def cosine(self,vec1,vec2):\n",
    "        return sum(self.dot(vec1,vec2))/(sqrt(sum(self.dot(vec1,vec1))*sqrt(sum(self.dot(vec2,vec2)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vsm_model=VSMOneHot([doc_1,doc_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of doc1:  0.32489377155287524\n",
      "score of doc2:  0.4300000760562836\n"
     ]
    }
   ],
   "source": [
    "print('score of doc1: ',vsm_model.score(q,doc_1))\n",
    "print('score of doc2: ',vsm_model.score(q,doc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from math import sqrt,log10\n",
    "from collections import defaultdict\n",
    "\n",
    "class VSMTFIDF():\n",
    "    \"\"\"vector space model-tfidf\"\"\"\n",
    "    def __init__(self ,doc_list):\n",
    "        self.stop_word_set=set([' ','$','——','-','.',',','/', '，', '；', \\\n",
    "                                '？','！','。','、','：','“','”',';',\\\n",
    "                                '@','是','让','了','的','啊','吧'])\n",
    "        self.doc_count=len(doc_list)   #idf的分子\n",
    "        self.vocabulary=[]\n",
    "        self.df=defaultdict(int)  #idf中的分母\n",
    "        for doc in doc_list:\n",
    "            doc_word_set=set(jieba.cut(doc.lower()))\n",
    "            for word in doc_word_set:\n",
    "                self.df[word]+=1\n",
    "            self.vocabulary+=list(jieba.cut(doc.lower()))\n",
    "        self.vocabulary=sorted(list(set(self.vocabulary)-self.stop_word_set))\n",
    "    \n",
    "    def score(self,q,doc):\n",
    "        vector_q=self.vectorize(q)\n",
    "        vector_doc=self.vectorize(doc)\n",
    "        return self.cosine(vector_q,vector_doc)\n",
    "        \n",
    "    def vectorize(self,doc):\n",
    "        result=[]\n",
    "        word_list=list(jieba.cut(doc.lower()))\n",
    "        #word_set=set(jieba.cut(doc.lower()))\n",
    "        for word in self.vocabulary:\n",
    "            tf=word_list.count(word)\n",
    "            idf=log10(self.doc_count/self.df[word]+0.02) ##容易产生除零错误\n",
    "            result.append(tf*idf)\n",
    "        return result\n",
    "    \n",
    "    def dot(self,vec1,vec2):\n",
    "        return [ vec1[i]* vec2[i] for i in range(len(self.vocabulary))]\n",
    "    \n",
    "    def cosine(self,vec1,vec2):\n",
    "        return sum(self.dot(vec1,vec2))/(sqrt(sum(self.dot(vec1,vec1))*sqrt(sum(self.dot(vec2,vec2)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsm_model=VSMTFIDF([doc_1,doc_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of doc1:  0.06095335931796388\n",
      "score of doc2:  0.013086113140839356\n"
     ]
    }
   ],
   "source": [
    "print('score of doc1: ',vsm_model.score(q,doc_1))\n",
    "print('score of doc2: ',vsm_model.score(q,doc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import bisect\n",
    "from collections import defaultdict\n",
    "import jieba\n",
    "import pickle\n",
    "\n",
    "class MySearchC5V1(MySearchC5V0):\n",
    "    \"\"\"\n",
    "    C3V0: Base class for Search Engine.\n",
    "    C3V1: Data multiplication added.\n",
    "    C3V2: Sorting optimization.\n",
    "    C3V3: Add lowered version of docs.\n",
    "    C3V4: For long doc.\n",
    "    C3V5: Caching search results.\n",
    "    C3V6: Pre-caching all words in docs.\n",
    "    C3V7: Add Serialize/UnSerialize.\n",
    "    C4V1: Add basic Bool query support\n",
    "    C4V2: Add wordseg to get_word_match()\n",
    "    ----------------C5V0-----------------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    filename : str\n",
    "        file name of doc data\n",
    "    multi_factor : int\n",
    "        data multiplication factor(default 1)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    load_data(filename):\n",
    "        load data from file.\n",
    "    save_data(filename):\n",
    "        save data to file\n",
    "    pre_cache_all():\n",
    "        Pre-caching all words in docs.\n",
    "    highlight(text, keyword):\n",
    "        highlight text with keyword.\n",
    "    score(text, keyword):\n",
    "        get score of text for a query.\n",
    "    get_word_match(self, keyword):\n",
    "        get doc set containing keyword.\n",
    "    search(keyword, num=15):\n",
    "        get top num search results of a query.\n",
    "    render(result_list, keyword):\n",
    "        output search results with highlight.\n",
    "    query_to_set_expression(query):\n",
    "        convert bool query to set expression(for eval process).\n",
    "    get_word_match(word):\n",
    "        get match set of the word.\n",
    "    ---------------------C5V0----------------------------\n",
    "    C5V1: use VSMTFIDF.score() as the score of search()\n",
    "        \n",
    "    \"\"\"\n",
    "    def search(self, query, num=15):\n",
    "        query_lower = query.lower()    \n",
    "        result_list = []\n",
    "        min_score = 0\n",
    "        query_new = self.query_to_set_expression(query_lower)\n",
    "        match_tid_list=list(eval(query_new))\n",
    "        vsm_model=VSMTFIDF([self.docs_lower[tid] for tid in match_tid_list])\n",
    "        result_list=[(tid,vsm_model.score(query_new,self.docs_lower[tid])) for tid in match_tid_list]\n",
    "        result_list.sort(key=lambda x:x[1],reverse=True)\n",
    "  \n",
    "        return [doc_id for doc_id, _ in result_list[:num]]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher=MySearchC5V1('c:/python data/titles_l.txt',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1、小学生们在b站讲算法 网友：我只会阿巴阿巴<br/>现在的b站知识区已经“内卷”成这样了？!6岁用递归实现斐波那契数列、8岁开讲神经网络如何实现、小学生教的编程比老师还要好，库克见了都点赞……最近，知识区内卷现状这样一个话题引发了热议，连清华的马少平教授也来围观：小孩蛮厉害的。不少网友着实有被内卷到......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2、iphone 14、14 pro/max大曝光：规格、售价都在这了<br/>有分析者认为iphone 14系列将于2022年9月亮相，尽管距离发布还有很长时间，但有关iphone 14系列的爆料已经流传网络。为方便大家了解iphone 14系列相关爆料，下面为大家做了详细整理。最早的爆料称，最近有消......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3、iphone 14 pro影像全面升级 或将采用4800万像素镜头<br/>按照往年的惯例，苹果将在今年九月发布全新一代的iphone 14系列。现在距离iphone 14系列发布越来越近，有关于这款新品的爆料也越来越多。近日分析师郭明錤发布了有关于iphone 14 pro系列的最新分析，他表示全......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4、iphone se3出货量将被下调一千万！销量未达预期<br/>今天，苹果知名分析师郭明錤在社交媒体发布消息，据悉，苹果之所以会直接下调一千万的出货量，实际上，iphone se3面临的这一局面，也并没有超出很多用户的预期。作为se系列的第三款产品，iphone se3首次搭载了a15仿生芯片，并支......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5、iphone 13/12量身打造！魅族磁吸手机壳明日限量发售<br/>今年初，魅族曾召开了一场“新生力量冬季新品发布会”，推出了pandaer品牌旗下的多款潮玩、配件类产品。很多老机型用户之前一直遗憾不能购买，同时，iphone 13的pandaer独角兽磁吸手机壳也将补货，限量开售。截至目前，pa......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6、换汤不换药？曝苹果准备将a15改版芯片命名为a16<br/>按照往年惯例，苹果会为新一代iphone配备最新的a系列芯片，但今年情况可能有些不一样。近期，天风国际分析师郭明錤爆料称，不过，近日有媒体表示自己获得最新消息，至于苹果公司为什么要这样做？媒体分析称，苹果及其合作伙伴正在努力制造a16 pr......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "7、中国联通2022首款5g旗舰发布！2299元起<br/>3月28日消息，今日晚间，中国联通自主5g手机品牌u-magic 2022年首款旗舰产品——优畅享50 plus正式发布，id设计上，优畅享50 plus背部镜组采用几何平衡、对称设计，镜头侧边为火山口+圆形deco双装饰方案，拥有雅致黑、珠贝......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "8、又一款钉子户手机诞生！实测一年半后依然不卡顿<br/>2022年的安卓旗舰手机标配皆为新骁龙8或天玑9000，虽然性能强大但售价高昂。俗话说“买新不买旧”，不过随着电子产品的迭代逐渐加快，曾经陪伴你的机器也许宝刀未老。笔者于20年10月首发购入了12gb+256gb顶配版的一加 8t手机，目前该机的......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query='手机 AND (苹果 or iphone)'\n",
    "search_result=searcher.search(query,num=10)\n",
    "searcher.render(search_result,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun search_result=searcher.search(query,num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from math import sqrt,log10\n",
    "from collections import defaultdict\n",
    "\n",
    "class VSMTFIDF():\n",
    "    \"\"\"vector space model-tfidf\"\"\"\n",
    "    def __init__(self ,doc_list):\n",
    "        self.stop_word_set=set([' ','$','——','-','.',',','/', '，', '；', \\\n",
    "                                '？','！','。','、','：','“','”',';',\\\n",
    "                                '@','是','让','了','的','啊','吧'])\n",
    "        self.doc_count=len(doc_list)   #idf的分子\n",
    "        self.vocabulary=[]\n",
    "        self.df=defaultdict(int)  #idf中的分母\n",
    "        self.tf=dict()\n",
    "        for doc in doc_list:\n",
    "            self.tf[doc]=defaultdict(int)\n",
    "            doc_word_set=set()\n",
    "            for word in jieba.cut(doc.lower()):\n",
    "                self.tf[doc][word]+=1\n",
    "                if word not in doc_word_set:\n",
    "                    self.df[word]+=1\n",
    "                    doc_word_set.add(word)\n",
    "            self.vocabulary+=list(jieba.cut(doc.lower()))\n",
    "        self.vocabulary=sorted(list(set(self.vocabulary)-self.stop_word_set))\n",
    "    \n",
    "    def score(self,q,doc):\n",
    "        vector_q=self.vectorize(q)\n",
    "        vector_doc=self.vectorize(doc)\n",
    "        return self.cosine(vector_q,vector_doc)\n",
    "        \n",
    "    def vectorize(self,doc):\n",
    "        result=[]\n",
    "        if doc not in self.tf:\n",
    "            word_list=list(jieba.cut(doc.lower()))\n",
    "        #word_set=set(jieba.cut(doc.lower()))\n",
    "        for word in self.vocabulary:\n",
    "            if doc in self.tf:\n",
    "                tf=self.tf[doc][word]\n",
    "            else:\n",
    "                tf=word_list.count(word)\n",
    "            idf=log10(self.doc_count/self.df[word]+0.02) ##容易产生除零错误\n",
    "            result.append(tf*idf)\n",
    "        return result\n",
    "    \n",
    "    def dot(self,vec1,vec2):\n",
    "        return [ vec1[i]* vec2[i] for i in range(len(self.vocabulary))]\n",
    "    \n",
    "    def cosine(self,vec1,vec2):\n",
    "        return sum(self.dot(vec1,vec2))/(sqrt(sum(self.dot(vec1,vec1))*sqrt(sum(self.dot(vec2,vec2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searcher=MySearchC5V1('c:/python data/titles_l.txt',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1、小学生们在b站讲算法 网友：我只会阿巴阿巴<br/>现在的b站知识区已经“内卷”成这样了？!6岁用递归实现斐波那契数列、8岁开讲神经网络如何实现、小学生教的编程比老师还要好，库克见了都点赞……最近，知识区内卷现状这样一个话题引发了热议，连清华的马少平教授也来围观：小孩蛮厉害的。不少网友着实有被内卷到......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2、iphone 14、14 pro/max大曝光：规格、售价都在这了<br/>有分析者认为iphone 14系列将于2022年9月亮相，尽管距离发布还有很长时间，但有关iphone 14系列的爆料已经流传网络。为方便大家了解iphone 14系列相关爆料，下面为大家做了详细整理。最早的爆料称，最近有消......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3、iphone 14 pro影像全面升级 或将采用4800万像素镜头<br/>按照往年的惯例，苹果将在今年九月发布全新一代的iphone 14系列。现在距离iphone 14系列发布越来越近，有关于这款新品的爆料也越来越多。近日分析师郭明錤发布了有关于iphone 14 pro系列的最新分析，他表示全......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4、iphone se3出货量将被下调一千万！销量未达预期<br/>今天，苹果知名分析师郭明錤在社交媒体发布消息，据悉，苹果之所以会直接下调一千万的出货量，实际上，iphone se3面临的这一局面，也并没有超出很多用户的预期。作为se系列的第三款产品，iphone se3首次搭载了a15仿生芯片，并支......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5、iphone 13/12量身打造！魅族磁吸手机壳明日限量发售<br/>今年初，魅族曾召开了一场“新生力量冬季新品发布会”，推出了pandaer品牌旗下的多款潮玩、配件类产品。很多老机型用户之前一直遗憾不能购买，同时，iphone 13的pandaer独角兽磁吸手机壳也将补货，限量开售。截至目前，pa......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6、换汤不换药？曝苹果准备将a15改版芯片命名为a16<br/>按照往年惯例，苹果会为新一代iphone配备最新的a系列芯片，但今年情况可能有些不一样。近期，天风国际分析师郭明錤爆料称，不过，近日有媒体表示自己获得最新消息，至于苹果公司为什么要这样做？媒体分析称，苹果及其合作伙伴正在努力制造a16 pr......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "7、中国联通2022首款5g旗舰发布！2299元起<br/>3月28日消息，今日晚间，中国联通自主5g手机品牌u-magic 2022年首款旗舰产品——优畅享50 plus正式发布，id设计上，优畅享50 plus背部镜组采用几何平衡、对称设计，镜头侧边为火山口+圆形deco双装饰方案，拥有雅致黑、珠贝......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "8、又一款钉子户手机诞生！实测一年半后依然不卡顿<br/>2022年的安卓旗舰手机标配皆为新骁龙8或天玑9000，虽然性能强大但售价高昂。俗话说“买新不买旧”，不过随着电子产品的迭代逐渐加快，曾经陪伴你的机器也许宝刀未老。笔者于20年10月首发购入了12gb+256gb顶配版的一加 8t手机，目前该机的......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query='手机 AND (苹果 or iphone)'\n",
    "search_result=searcher.search(query,num=10)\n",
    "searcher.render(search_result,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun search_result=searcher.search(query,num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25(Okapi BM25)  \n",
    "#### BM25是信息索引领域用来计算query与文档相似度得分的经典算法。\n",
    "\\begin{equation}\n",
    "\\operatorname{score}(D, Q)=\\sum_{i=1}^{n} \\operatorname{IDF}\\left(q_{i}\\right) \\cdot \\frac{f\\left(q_{i}, D\\right) \\cdot\\left(k_{1}+1\\right)}{f\\left(q_{i}, D\\right)+k_{1} \\cdot\\left(1-b+b \\cdot \\frac{|D|}{\\text { avgdl }}\\right)}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\operatorname{IDF}\\left(q_{i}\\right)=\\ln \\left(\\frac{N-n\\left(q_{i}\\right)+0.5}{n\\left(q_{i}\\right)+0.5}+1\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from collections import defaultdict\n",
    "import jieba\n",
    "\n",
    "class BM25():\n",
    "    def __init__(self,doc_list):\n",
    "        self.doc_count=len(doc_list)   # N\n",
    "        self.avgdl=0\n",
    "        self.df=defaultdict(int)      # n\n",
    "        for doc in doc_list:\n",
    "            for word in set(jieba.cut(doc.lower())):\n",
    "                self.df[word]+=1     \n",
    "            self.avgdl+=len(doc)\n",
    "        self.avgdl=self.avgdl/self.doc_count   #  avgdl \n",
    "        \n",
    "    \n",
    "    def score(self,q,doc):\n",
    "        k1=1.5\n",
    "        b=0.75\n",
    "        result=0\n",
    "        \n",
    "        query_new=set(jieba.cut(q))-set(['(',')','and','AND','+','or','OR','NOT','not',\\\n",
    "                                                '-','',' '])\n",
    "        word_list_doc=list(jieba.cut(doc.lower()))\n",
    "        \n",
    "        for keyword in query_new:\n",
    "            f=word_list_doc.count(keyword)   # 公式当中的f，实质上就是tf\n",
    "            dl=len(doc)               # |D|\n",
    "            idf=log((self.doc_count-self.df[keyword]+0.5)/(self.df[keyword]+0.5)+1)\n",
    "            result+=idf*(f*(k1+1))/(f+k1*(1-b+b*dl/self.avgdl))\n",
    "        return result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm25_model=BM25([doc_1,doc_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8122865582866411\n",
      "0.6268363247332946\n"
     ]
    }
   ],
   "source": [
    "print(bm25_model.score(q,doc_1))\n",
    "print(bm25_model.score(q,doc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import bisect\n",
    "from collections import defaultdict\n",
    "import jieba\n",
    "import pickle\n",
    "\n",
    "class MySearchC5V2(MySearchC5V0):\n",
    "    \"\"\"\n",
    "    C3V0: Base class for Search Engine.\n",
    "    C3V1: Data multiplication added.\n",
    "    C3V2: Sorting optimization.\n",
    "    C3V3: Add lowered version of docs.\n",
    "    C3V4: For long doc.\n",
    "    C3V5: Caching search results.\n",
    "    C3V6: Pre-caching all words in docs.\n",
    "    C3V7: Add Serialize/UnSerialize.\n",
    "    C4V1: Add basic Bool query support\n",
    "    C4V2: Add wordseg to get_word_match()\n",
    "    ----------------C5V0-----------------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    filename : str\n",
    "        file name of doc data\n",
    "    multi_factor : int\n",
    "        data multiplication factor(default 1)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    load_data(filename):\n",
    "        load data from file.\n",
    "    save_data(filename):\n",
    "        save data to file\n",
    "    pre_cache_all():\n",
    "        Pre-caching all words in docs.\n",
    "    highlight(text, keyword):\n",
    "        highlight text with keyword.\n",
    "    score(text, keyword):\n",
    "        get score of text for a query.\n",
    "    get_word_match(self, keyword):\n",
    "        get doc set containing keyword.\n",
    "    search(keyword, num=15):\n",
    "        get top num search results of a query.\n",
    "    render(result_list, keyword):\n",
    "        output search results with highlight.\n",
    "    query_to_set_expression(query):\n",
    "        convert bool query to set expression(for eval process).\n",
    "    get_word_match(word):\n",
    "        get match set of the word.\n",
    "    ---------------------C5V0----------------------------\n",
    "    C5V2: use BM25.score() as the score of search()\n",
    "        \n",
    "    \"\"\"\n",
    "    def search(self, query, num=15):\n",
    "        query_lower = query.lower()    \n",
    "        result_list = []\n",
    "        min_score = 0\n",
    "        query_new = self.query_to_set_expression(query_lower)\n",
    "        match_tid_list=list(eval(query_new))\n",
    "        bm25_model=BM25([self.docs_lower[tid] for tid in match_tid_list])\n",
    "        \"\"\"\n",
    "        query_new123=set(jieba.cut(query_lower))-set(['(',')','and','AND','+','or','OR','NOT','not',\\\n",
    "                                                '-','',' '])\n",
    "        \"\"\"\n",
    "        \n",
    "        result_list=[(tid,bm25_model.score(query_lower,self.docs_lower[tid])) for tid in match_tid_list]\n",
    "        result_list.sort(key=lambda x:x[1],reverse=True)\n",
    "  \n",
    "        return [doc_id for doc_id, _ in result_list[:num]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searcher=MySearchC5V2('c:/python data/titles_l.txt',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1、iphone 14、14 pro/max大曝光：规格、售价都在这了<br/>有分析者认为iphone 14系列将于2022年9月亮相，尽管距离发布还有很长时间，但有关iphone 14系列的爆料已经流传网络。为方便大家了解iphone 14系列相关爆料，下面为大家做了详细整理。最早的爆料称，最近有消......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2、iphone se3出货量将被下调一千万！销量未达预期<br/>今天，苹果知名分析师郭明錤在社交媒体发布消息，据悉，苹果之所以会直接下调一千万的出货量，实际上，iphone se3面临的这一局面，也并没有超出很多用户的预期。作为se系列的第三款产品，iphone se3首次搭载了a15仿生芯片，并支......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3、换汤不换药？曝苹果准备将a15改版芯片命名为a16<br/>按照往年惯例，苹果会为新一代iphone配备最新的a系列芯片，但今年情况可能有些不一样。近期，天风国际分析师郭明錤爆料称，不过，近日有媒体表示自己获得最新消息，至于苹果公司为什么要这样做？媒体分析称，苹果及其合作伙伴正在努力制造a16 pr......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4、iphone 14 pro影像全面升级 或将采用4800万像素镜头<br/>按照往年的惯例，苹果将在今年九月发布全新一代的iphone 14系列。现在距离iphone 14系列发布越来越近，有关于这款新品的爆料也越来越多。近日分析师郭明錤发布了有关于iphone 14 pro系列的最新分析，他表示全......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5、iphone 13/12量身打造！魅族磁吸手机壳明日限量发售<br/>今年初，魅族曾召开了一场“新生力量冬季新品发布会”，推出了pandaer品牌旗下的多款潮玩、配件类产品。很多老机型用户之前一直遗憾不能购买，同时，iphone 13的pandaer独角兽磁吸手机壳也将补货，限量开售。截至目前，pa......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6、中国联通2022首款5g旗舰发布！2299元起<br/>3月28日消息，今日晚间，中国联通自主5g手机品牌u-magic 2022年首款旗舰产品——优畅享50 plus正式发布，id设计上，优畅享50 plus背部镜组采用几何平衡、对称设计，镜头侧边为火山口+圆形deco双装饰方案，拥有雅致黑、珠贝......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "7、又一款钉子户手机诞生！实测一年半后依然不卡顿<br/>2022年的安卓旗舰手机标配皆为新骁龙8或天玑9000，虽然性能强大但售价高昂。俗话说“买新不买旧”，不过随着电子产品的迭代逐渐加快，曾经陪伴你的机器也许宝刀未老。笔者于20年10月首发购入了12gb+256gb顶配版的一加 8t手机，目前该机的......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "8、小学生们在b站讲算法 网友：我只会阿巴阿巴<br/>现在的b站知识区已经“内卷”成这样了？!6岁用递归实现斐波那契数列、8岁开讲神经网络如何实现、小学生教的编程比老师还要好，库克见了都点赞……最近，知识区内卷现状这样一个话题引发了热议，连清华的马少平教授也来围观：小孩蛮厉害的。不少网友着实有被内卷到......"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query='手机 AND (苹果 or iphone)'\n",
    "search_result=searcher.search(query,num=10)\n",
    "searcher.render(search_result,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jieba.load_uerdict('./dict.txt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
